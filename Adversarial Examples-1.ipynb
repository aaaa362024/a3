{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Adversarial-Machine-Learning\">Adversarial Machine Learning<a class=\"anchor-link\" href=\"#Adversarial-Machine-Learning\">¶</a></h1><h2 id=\"Practice-Session:-Adversarial-Example\">Practice Session: Adversarial Examples<a class=\"anchor-link\" href=\"#Practice-Session:-Adversarial-Example\">¶</a></h2><p>In this practice, we will introduce an important attack method: adversarial example, which is executed against the machine learning model (deep learning or neural network). The dataset we will use today is the MNIST dataset of hand-written digitals. Please refer to details of the dataset at <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>.</p>\n",
    "<p>As we introduced in this module, adversarial examples are produced by adding some noise on the original image which can lead to a mis-classification from the machine learning model. In today's demonstration, we will train a deep learning model using the same technique as last week, and test its accuracy. We will then choose one image from the training dataset and add some randomised noise on it, and check the prediction result from the deep learning model to see if the model will mis-classify this noisy image.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Firstly, we will import some packages. As you can see below, we'll be using numpy, as well as the <strong>Pytorch</strong> package to construct our neural network for the deep learning model, so ensure you have installed this using the information in your orientation materials.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next, we declare some hyper parameters for model training, including <strong>training epochs</strong>, <strong>batch size</strong> and <strong>learning rate</strong>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper Parameters\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE1 = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, we need to load our <strong>training dataset</strong> and <strong>test dataset</strong>. We're using the MNIST dataset, which is already built in Pytorch's torchvision package. We now load training dataset and test dataset from torchvision.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = [0.5],std = [0.5])\n",
    "                               ])\n",
    "\n",
    "# Download training dataset\n",
    "train_dataset = dsets.MNIST(root = './data/',\n",
    "                            train = True, \n",
    "                            transform = transform,\n",
    "                            download = True)\n",
    "\n",
    "# Download testing dataset\n",
    "test_dataset = dsets.MNIST(root = './data/',\n",
    "                           train = False, \n",
    "                           transform = transform,\n",
    "                           download = True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "# The first training dataset for target model\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = BATCH_SIZE, \n",
    "                                           shuffle = True)\n",
    "\n",
    "# The original test dataset\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's see the number of images in these datasets. Click run to ouput these numbers.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The length of training dataset: \", len(train_dataset))\n",
    "print(\"The length of test dataset: \", len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So we can see that we have 60000 training images and 10000 test images for digits from 0 to 9.</p>\n",
    "\n",
    "<p>Now, let's show the first image of the whole training dataset.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The training data includes two parts, the <strong>image information</strong> and its <strong>label</strong>. As the result above shows, the first image of the entire training dataset is 5. Let's now print out the image. We will import the matplotlib package and use the <strong>imshow</strong> function, which generates images based on 2-dimensional numpy arrays.</p> You can show any image from the data set by changing the first value following train_dataset. Try it now by entering any number between 0 and 59999, but don't forget to return to the original value 0 before you continue. If you want to show more than one image from the dataset, simply copy the last four lines of code, paste it below the existing code and specifiy the image you would like to display.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "img = train_dataset[0][0].squeeze(0).data\n",
    "img = img.numpy()\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, let's build our model. In the code below, we construct a 4-layer neural network for our deep learning model. This is deep enough for this dataset to reach a very high test accuracy. We use <strong>Cross Entropy Loss</strong> to calculate the gap between the predicted label and real label.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),\n",
    "            nn.BatchNorm2d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),\n",
    "            nn.BatchNorm2d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),             \n",
    "            nn.BatchNorm2d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features = 8192, out_features = 50, bias = True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(in_features = 50, out_features = 10, bias = True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Define a model cnn belongs to CNN class\n",
    "classifierModel = Classifier()\n",
    "# Loss and Optimizer\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(classifierModel.parameters(), lr = LEARNING_RATE1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's train our model. We train the model for 10 epochs, which means all training data will pass the model 10 times. The training process may cost different lengths of time due to the difference of calculation capability between different devices.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the Model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "#         print(labels)\n",
    "#         print(type(labels))\n",
    "        \n",
    "#         labels = dirtyLabel(labels, 7, 1)\n",
    "#         print(labels)\n",
    "#         print(type(labels))\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer1.zero_grad()\n",
    "        outputs = classifierModel(images)\n",
    "        \n",
    "        loss = criterion1(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch + 1, NUM_EPOCHS, i + 1, len(train_dataset)//BATCH_SIZE, loss.data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's test our model using the test dataset. Click 'run' to output an accuracy report for the ten digits.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the Model\n",
    "classifierModel.eval() # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "correct0 = correct1 = correct2 = correct3 = correct4 = correct5 = correct6 = correct7 = correct8 = correct9 = 0\n",
    "total0 = total1 = total2 = total3 = total4 = total5 = total6 = total7 = total8 = total9 = 0\n",
    "\n",
    "names = locals()\n",
    "\n",
    "for images, labels in test_loader:            \n",
    "    images = Variable(images)\n",
    "    outputs = classifierModel(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    labels = labels.tolist()\n",
    "    for l in range(0, 10):\n",
    "        if labels[0] == l:\n",
    "            names[\"total\" + str(l)] = names[\"total\" + str(l)] + 1\n",
    "            predicted = predicted.tolist()\n",
    "            if predicted[0] == labels[0]:\n",
    "                names[\"correct\" + str(l)] = names[\"correct\" + str(l)] + 1\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * float(correct) / total))\n",
    "\n",
    "for num in range(0, 10):\n",
    "    print(\"Test Accuracy of the model on the number\", num, \"is: %d %%\" % (100 * float(names[\"correct\" + str(num)]) / names[\"total\" + str(num)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The result above shows that our model can reach over 99% accuracy. Now, let's test the predicted label for the image 5 we printed out.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifierModel.eval()\n",
    "images = torch.tensor(img, dtype = torch.float32)\n",
    "images = images.unsqueeze(0)\n",
    "images = images.unsqueeze(0)\n",
    "print(images.shape)\n",
    "print(images.type())\n",
    "images = Variable(images)\n",
    "outputs = classifierModel(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an adversarial image\n",
    "\n",
    "<p>Let's make this image \"adversarial\" by adding some perturbed noise on this image. The image will look similar to the original image, so to us it will still look like the number 5. However, our trained model will mis-classify it as another digit.</p>\n",
    "<p>Firstly, we generate a noisy tensor with the same shape as our original image, 32 x 32 pixels. We use the <strong>random</strong> function of the numpy package to generate a random noise matrix. We need to carefully scale the noise and guarantee the noise won't change the image visually too much. The <strong>random.random()</strong> function will generate a random number in the range (0,1).</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noiseMatrix = np.random.random((32,32))\n",
    "print(noiseMatrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We add our generated noise on the original image, and print out the noisy image.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = img + noiseMatrix \n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>From the new perturbed image we can find that, although the image is noisy comparing with the original image, we can still visually recognise the number from the perturbed image is 5. Now, we need to convert the numpy matrix of the image to a tensor, for the deep learning model to do the prediction.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = torch.tensor(img1, dtype = torch.float32)\n",
    "images = images.unsqueeze(0)\n",
    "images = images.unsqueeze(0)\n",
    "print(images.shape)\n",
    "print(images.type())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, let's bring this perturbed image to our trained model, and see the prediction result.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifierModel.eval()\n",
    "images = Variable(images)\n",
    "outputs = classifierModel(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The prediction result from the deep learning model now is changed to 8. This is our adversarial example against a deep learning model.</p>\n",
    "<p>Finally, we scale the perturbation and see the comparison between the original image and perturbed images, and the prediction results from the deep learning model.</p>\n",
    "<p>We scale down our noise to 1/2, 1/3, 1/4 and 1/5.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2, 6):\n",
    "    \n",
    "    img1 = img + noiseMatrix / i\n",
    "    print(\"----- Noise is scaled down to 1/%d ----\" % i)\n",
    "    plt.figure(1)\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(img1)\n",
    "    plt.show()\n",
    "    \n",
    "    images = torch.tensor(img1, dtype = torch.float32)\n",
    "    images = images.unsqueeze(0)\n",
    "    images = images.unsqueeze(0)\n",
    "    \n",
    "    classifierModel.eval()\n",
    "    images = Variable(images)\n",
    "    outputs = classifierModel(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    print(\"-- The prediction result now is: %d --\" % predicted.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>From the results above, you can see that the image looks clearer as the noise gets smaller, but the prediction result tends to be become more accurate. Therefore, it's important for an attacker to add the smallest possible amount of noise on the original image to guarantee visual clarity that will still mislead the machine learning model to mis-classify it.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
