# -*- coding: utf-8 -*-
"""Copy of Assessment 3a-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12dE-PRFkzYK3FoyLrh2Q6NbeNowr5D0_

# Assessment 3a: Generating adversarial examples

In this assessment, you are required to generate five adversarial example images to fool a machine learning model into misclassifying them. This assessment is quite similar to the practical session, so please carefully read the practical session and understand its content before you go through this assessment.

The dataset you will be using is FashionMNST, a series of images of different types of clothing. Each image is classified according to 10 different types of clothing.

![fashion-mnist.png](attachment:fashion-mnist.png)

Each training and test example is assigned to one of the following labels:

| Label	| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |:---: | :---: |:---: | :---: |
|  | T-shirt/top| Trouser | Pullover | Dress | Coat | Sandal | Shirt | Sneaker | Bag | Ankle boot |

Now you need to create a list named as "classes" to store these labels in String, and print this list.

Expected outputs:

    ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
"""

classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot' ]
print(classes)
print(classes[5])

"""Before we go through training the deep learning model, please import the necessary packages. These will be the same as those we introduced in the Module 4 and 5 practical activities."""

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.autograd import Variable

import numpy as np
import math
import random

"""
<p>Next, we declare some hyper parameters for model training, including <strong>training epochs</strong>, <strong>batch size</strong> and <strong>learning rate</strong>.
    
Training epochs can be set as any integer number greater than 10. Batch size can be set as any number from 32, 64, 100. Learning rate should be set as 0.001</p>
"""

# Hyper Parameters
NUM_EPOCHS = 3
BATCH_SIZE = 100
LEARNING_RATE1 = 0.001

"""Load the training dataset test dataset. The name of required dataset is "FashionMNIST". To get this dataset, simply replace 'MNIST' in the practical session as 'FashionMNIST'."""

# MNIST Dataset
transform = transforms.Compose([transforms.Resize((32, 32)),
                                transforms.ToTensor(),
                                transforms.Normalize(mean = [0.5],std = [0.5])
                               ])

# Download training dataset
train_dataset = dsets.FashionMNIST(root = './data/',
                            train = True,
                            transform = transform,
                            download = True)

# Download testing dataset
test_dataset = dsets.FashionMNIST(root = './data/',
                           train = False,
                           transform = transform,
                           download = True)

# Data Loader (Input Pipeline)
# The first training dataset for target model
train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)

# The original test dataset
test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                          shuffle = False)

"""
Please print the number of how many images from both training dataset and test dataset.</p>

Expected output is:

    The length of training dataset:  60000

    The length of test dataset:  """

print("The length of training dataset: ", len(train_dataset))
print("The length of test dataset: ", len(test_dataset))

"""
Show the first 5 images of the training dataset to see what they look like.</p>

In this assessment, you are required to demonstrate and create adversarial examples for the first five images. Simply change the index of the training dataset and create five different variables for five images.

Example for the third image:
    
    img3 = training_dataset[2][0].squeeze(0).data
    """

import matplotlib.pyplot as plt
img1 = train_dataset[0][0].squeeze(0).data
img1 = img1.numpy()
plt.imshow(img1)
plt.show()

import matplotlib.pyplot as plt
img2 = train_dataset[1][0].squeeze(0).data
img2 = img2.numpy()
plt.imshow(img2)
plt.show()

import matplotlib.pyplot as plt
img3 = train_dataset[2][0].squeeze(0).data
img3 = img3.numpy()
plt.imshow(img3)
plt.show()

import matplotlib.pyplot as plt
img4 = train_dataset[3][0].squeeze(0).data
img4 = img4.numpy()
plt.imshow(img4)
plt.show()

import matplotlib.pyplot as plt
img5 = train_dataset[4][0].squeeze(0).data
img5 = img5.numpy()
plt.imshow(img5)
plt.show()

"""<p>In this assessment we will use the same model as our practical activities to build and train the model. Use the code from the practical activity to add the model.</p>"""

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 128, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),
            nn.BatchNorm2d(128, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),
            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),
            nn.ReLU(inplace = True)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),
            nn.BatchNorm2d(256, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),
            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),
            nn.ReLU(inplace = True)
        )
        self.layer3 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1)),
            nn.BatchNorm2d(512, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True),
            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False),
            nn.ReLU(inplace = True)
        )
        self.fc = nn.Sequential(
            nn.Linear(in_features = 8192, out_features = 50, bias = True),
            nn.Dropout(p = 0.5),
            nn.Linear(in_features = 50, out_features = 10, bias = True)
        )

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out

# Define a model cnn belongs to CNN class
classifierModel = Classifier()
# Loss and Optimizer
criterion1 = nn.CrossEntropyLoss()
optimizer1 = torch.optim.Adam(classifierModel.parameters(), lr = LEARNING_RATE1)

"""
<p>Let's train our model. We train the model for the number of epochs you set above, which means all training data will pass the model that number times. The training process may take different lengths of time depending on the the processing capability between different devices. Again, you will need to add the correct code from the practical activity.</p>
"""

# Commented out IPython magic to ensure Python compatibility.
# Train the Model
for epoch in range(NUM_EPOCHS):
    for i, (images, labels) in enumerate(train_loader):
#         print(labels)
#         print(type(labels))

#         labels = dirtyLabel(labels, 7, 1)
#         print(labels)
#         print(type(labels))
        images = Variable(images)
        labels = Variable(labels)

        # Forward + Backward + Optimize
        optimizer1.zero_grad()
        outputs = classifierModel(images)

        loss = criterion1(outputs, labels)
        loss.backward()
        optimizer1.step()

        if (i + 1) % 100 == 0:
            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'
#                    %(epoch + 1, NUM_EPOCHS, i + 1, len(train_dataset)//BATCH_SIZE, loss.data))

"""
<p>Let's test our model using test dataset. You are required to show the test accuracy of 1000 test images. You are also required to show the test accuracy of the model on each class (classes' names are created above already. Simply use classes[n], n is an integer of the label. For example, 'T-shirt/top' is classes[0])</p>

Example output:

Test Accuracy of the model on the 10000 test images: ** %

Test Accuracy of the model on the class T-shirt/top is: ** %

..."""

# Test the Model
classifierModel.eval() # Change model to 'eval' mode (BN uses moving mean/var).

correct = 0
total = 0
correct0 = correct1 = correct2 = correct3 = correct4 = correct5 = correct6 = correct7 = correct8 = correct9 = 0
total0 = total1 = total2 = total3 = total4 = total5 = total6 = total7 = total8 = total9 = 0

names = locals()

for images, labels in test_loader:
    images = Variable(images)
    outputs = classifierModel(images)
    _, predicted = torch.max(outputs.data, 1)

    total += labels.size(0)
    correct += (predicted == labels).sum()

    labels = labels.tolist()
    for l in range(0, 10):
        if labels[0] == l:
            names["total" + str(l)] = names["total" + str(l)] + 1
            predicted = predicted.tolist()
            if predicted[0] == labels[0]:
                names["correct" + str(l)] = names["correct" + str(l)] + 1

print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * float(correct) / total))

for num in range(0, 10):
    print("Test Accuracy of the model on the class",classes[num], "is: %d %%" % (100 * float(names["correct" + str(num)]) / names["total" + str(num)]))

"""
Test the predicted label for the first image of training dataset which is already printed out above.

Expected output:

    "Trouser"
"""

classifierModel.eval()
images = torch.tensor(img1, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

"""## Make your adversarial images

To make adversarial images, some peturbed noise with the same shape as the original images(32 * 32) should be generated. As the demonstration in the pratical session, the adversarial image maybe not visually clear when the noise is large, and also the adversarial image cannot fool the deep learning model when the noise is small. Please carefully scale the noise. The task is to generate the small enough noise to fool the deep learning model.

And then add generated noise on 5 original images, and print out 5 noisy images. Please note, you only need to generate noise and make adversarial examples for first five images we print above.

Show 5 adversarial images, their original label, and their predicted labels from the deep learning model.
Also print out 5 original images and 5 adversarial images as comparision.
"""

noiseMatrix = np.random.random((32,32))
print(noiseMatrix)



noisyimg1 = img1 +noiseMatrix
plt.imshow(noisyimg1)
plt.show()

images = torch.tensor(noisyimg1, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
print(images.shape)
print(images.type())

classifierModel.eval()
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

noiseMatrix = np.random.random((32,32))
print(noiseMatrix)

noisyimg2 = img2 + noiseMatrix
plt.imshow(noisyimg2)
plt.show()

images = torch.tensor(noisyimg2, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
print(images.shape)
print(images.type())

classifierModel.eval()
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

noiseMatrix = np.random.random((32,32))
print(noiseMatrix)

noisyimg3 = img3 + noiseMatrix
plt.imshow(noisyimg3)
plt.show()

images = torch.tensor(noisyimg3, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
print(images.shape)
print(images.type())

classifierModel.eval()
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

noiseMatrix = np.random.random((32,32))
print(noiseMatrix)

noisyimg4 = img4 + noiseMatrix
plt.imshow(noisyimg4)
plt.show()

images = torch.tensor(noisyimg4, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
print(images.shape)
print(images.type())

classifierModel.eval()
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

noiseMatrix = np.random.random((32,32))
print(noiseMatrix)

noisyimg5 = img5 + noiseMatrix
plt.imshow(noisyimg5)
plt.show()

images = torch.tensor(noisyimg5, dtype = torch.float32)
images = images.unsqueeze(0)
images = images.unsqueeze(0)
print(images.shape)
print(images.type())

classifierModel.eval()
images = Variable(images)
outputs = classifierModel(images)
_, predicted = torch.max(outputs.data, 1)
print(classes[predicted])

